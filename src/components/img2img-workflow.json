{
  "2": {
    "inputs": {
      "text": [
        "3",
        0
      ],
      "text2": ", sharp photo of a close-up of a large tree with its branches reaching up towards the sky. The tree appears to be in a forest or a wooded area, as there are other trees and shrubs visible in the background. The leaves on the tree are vibrant and colorful, with shades of orange, yellow, and red. The branches are twisted and gnarled, creating a sense of depth and texture. The ground below the tree is covered in green moss, and there is a large rock on the left side of the image. The sunlight is shining through the leaves, casting a warm glow on the scene."
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "3": {
    "inputs": {
      "text1": [
        "6",
        0
      ],
      "text2": [
        "5",
        0
      ],
      "separator": ", "
    },
    "class_type": "CR Text Concatenate",
    "_meta": {
      "title": "üî§ CR Text Concatenate"
    }
  },
  "4": {
    "inputs": {
      "text": [
        "7",
        0
      ],
      "find": "The image shows",
      "replace": "sharp photo of"
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "Text Find and Replace"
    }
  },
  "5": {
    "inputs": {
      "text": [
        "4",
        0
      ],
      "find": "The image is",
      "replace": "sharp photo of"
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "Text Find and Replace"
    }
  },
  "6": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "7": {
    "inputs": {
      "text": [
        "8",
        2
      ],
      "text2": "The image is a close-up of a large tree with its branches reaching up towards the sky. The tree appears to be in a forest or a wooded area, as there are other trees and shrubs visible in the background. The leaves on the tree are vibrant and colorful, with shades of orange, yellow, and red. The branches are twisted and gnarled, creating a sense of depth and texture. The ground below the tree is covered in green moss, and there is a large rock on the left side of the image. The sunlight is shining through the leaves, casting a warm glow on the scene."
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "8": {
    "inputs": {
      "text_input": "",
      "task": "more_detailed_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "image": [
        "28",
        0
      ],
      "florence2_model": [
        "9",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "9": {
    "inputs": {
      "model": "gokaygokay/Florence-2-Flux-Large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "10": {
    "inputs": {
      "text": [
        "2",
        0
      ],
      "clip": [
        "12",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Florence"
    }
  },
  "11": {
    "inputs": {
      "unet_name": "flux1-dev-fp8.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "12": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "13": {
    "inputs": {
      "vae_name": "flux\\ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "14": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "10",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "15": {
    "inputs": {
      "noise": [
        "17",
        0
      ],
      "guider": [
        "16",
        0
      ],
      "sampler": [
        "19",
        0
      ],
      "sigmas": [
        "21",
        0
      ],
      "latent_image": [
        "22",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "16": {
    "inputs": {
      "model": [
        "20",
        0
      ],
      "conditioning": [
        "14",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "17": {
    "inputs": {
      "noise_seed": 534053971469892
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "18": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "19": {
    "inputs": {
      "dishonesty_factor": -0.05,
      "start_percent": 0.1,
      "end_percent": 0.9,
      "sampler": [
        "18",
        0
      ]
    },
    "class_type": "LyingSigmaSampler",
    "_meta": {
      "title": "Lying Sigma Sampler"
    }
  },
  "20": {
    "inputs": {
      "max_shift": 1.1500000000000001,
      "base_shift": 0.5,
      "width": [
        "23",
        0
      ],
      "height": [
        "23",
        1
      ],
      "model": [
        "11",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "ModelSamplingFlux"
    }
  },
  "21": {
    "inputs": {
      "scheduler": "beta",
      "steps": 20,
      "denoise": 1,
      "model": [
        "20",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "22": {
    "inputs": {
      "width": [
        "23",
        0
      ],
      "height": [
        "23",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "23": {
    "inputs": {
      "width": 400,
      "height": 1600,
      "aspect_ratio": "SDXL - 9:16 portrait 768x1344",
      "swap_dimensions": "On",
      "upscale_factor": 1,
      "prescale_factor": 1,
      "batch_size": 1
    },
    "class_type": "CR Aspect Ratio",
    "_meta": {
      "title": "üî≥ CR Aspect Ratio"
    }
  },
  "24": {
    "inputs": {
      "samples": [
        "15",
        0
      ],
      "vae": [
        "13",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "27": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "subdirectory_name": "",
      "output_format": "png",
      "quality": "max",
      "metadata_scope": "full",
      "include_batch_num": true,
      "images": [
        "24",
        0
      ]
    },
    "class_type": "SaveImageWithMetaData",
    "_meta": {
      "title": "Save Image With Metadata"
    }
  },
  "28": {
    "inputs": {
      "image": "forest-photography (1).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  }
}